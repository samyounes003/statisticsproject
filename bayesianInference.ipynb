{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, LotAreaEffect, NeighborhoodEffect, OverallQualEffect, YearBuiltEffect, GrLivAreaEffect, GarageCarsEffect, FullBathEffect, FireplacesEffect, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:08&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 9 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        mean      sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
      "Intercept            322.861   9.932   304.611   342.503      0.143    0.101   \n",
      "LotAreaEffect          3.928   9.959   -14.562    23.363      0.134    0.151   \n",
      "NeighborhoodEffect  3839.083   9.039  3822.001  3855.394      0.119    0.084   \n",
      "OverallQualEffect   2175.798   9.800  2158.185  2194.269      0.132    0.093   \n",
      "YearBuiltEffect      100.973   9.931    81.689   119.075      0.127    0.091   \n",
      "GrLivAreaEffect        0.504  10.058   -18.145    19.275      0.129    0.169   \n",
      "GarageCarsEffect     660.089  10.151   639.708   678.018      0.132    0.093   \n",
      "FullBathEffect       564.147  10.028   545.250   582.416      0.121    0.085   \n",
      "FireplacesEffect     257.942   9.851   239.859   276.440      0.131    0.093   \n",
      "sigma               7307.290   5.759  7296.496  7318.231      0.077    0.054   \n",
      "\n",
      "                    ess_bulk  ess_tail  r_hat  \n",
      "Intercept             4848.0    3115.0    1.0  \n",
      "LotAreaEffect         5529.0    2863.0    1.0  \n",
      "NeighborhoodEffect    5733.0    3395.0    1.0  \n",
      "OverallQualEffect     5546.0    2969.0    1.0  \n",
      "YearBuiltEffect       6136.0    3080.0    1.0  \n",
      "GrLivAreaEffect       6146.0    2913.0    1.0  \n",
      "GarageCarsEffect      5905.0    2726.0    1.0  \n",
      "FullBathEffect        6922.0    3064.0    1.0  \n",
      "FireplacesEffect      5643.0    3021.0    1.0  \n",
      "sigma                 5645.0    3108.0    1.0  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Select relevant features\n",
    "selected_features = ['LotArea', 'Neighborhood', 'OverallQual', 'YearBuilt',\n",
    "                     'GrLivArea', 'GarageCars', 'FullBath', 'Fireplaces', 'SalePrice']\n",
    "\n",
    "\n",
    "# Encoding 'Neighborhood' as a categorical variable\n",
    "data['Neighborhood'] = pd.Categorical(data['Neighborhood']).codes\n",
    "\n",
    "# Normalize numerical predictors for better numerical stability\n",
    "data['LotArea'] = data['LotArea'] / 1000  # Scale to 1000s of square feet\n",
    "data['YearBuilt'] = (data['YearBuilt'] - data['YearBuilt'].mean()) / data['YearBuilt'].std()\n",
    "data['GrLivArea'] = data['GrLivArea'] / 1000  # Scale to 1000s of square feet\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[[i for i in data.columns if i not in ['SalePrice']]], data.SalePrice, test_size=0.2, random_state=42)\n",
    "X_train['SalePrice'] = list(y_train)\n",
    "\n",
    "# Start the Bayesian Model\n",
    "with pm.Model() as housing_model:\n",
    "    # Priors for coefficients\n",
    "    beta_0 = pm.Normal('Intercept', mu=0, sigma=10)  # Prior for the intercept\n",
    "    beta_LotArea = pm.Normal('LotAreaEffect', mu=0, sigma=10)\n",
    "    beta_Neighborhood = pm.Normal('NeighborhoodEffect', mu=0, sigma=10)\n",
    "    beta_OverallQual = pm.Normal('OverallQualEffect', mu=0, sigma=10)\n",
    "    beta_YearBuilt = pm.Normal('YearBuiltEffect', mu=0, sigma=10)\n",
    "    beta_GrLivArea = pm.Normal('GrLivAreaEffect', mu=0, sigma=10)\n",
    "    beta_GarageCars = pm.Normal('GarageCarsEffect', mu=0, sigma=10)\n",
    "    beta_FullBath = pm.Normal('FullBathEffect', mu=0, sigma=10)\n",
    "    beta_Fireplaces = pm.Normal('FireplacesEffect', mu=0, sigma=10)\n",
    "\n",
    "    # Likelihood (data-generating process)\n",
    "    mu = (\n",
    "        beta_0 +\n",
    "        beta_LotArea * data['LotArea'] +\n",
    "        beta_Neighborhood * data['Neighborhood'] +\n",
    "        beta_OverallQual * data['OverallQual'] +\n",
    "        beta_YearBuilt * data['YearBuilt'] +\n",
    "        beta_GrLivArea * data['GrLivArea'] +\n",
    "        beta_GarageCars * data['GarageCars'] +\n",
    "        beta_FullBath * data['FullBath'] +\n",
    "        beta_Fireplaces * data['Fireplaces']\n",
    "    )\n",
    "\n",
    "    sigma = pm.HalfNormal('sigma', sigma=10)  # Prior for residual noise\n",
    "    price_obs = pm.Normal('Price', mu=mu, sigma=sigma, observed=data['SalePrice'])\n",
    "\n",
    "    # Explicitly create a compatible random number generator\n",
    "    rng = np.random.default_rng(42)  # Random seed for reproducibility\n",
    "    \n",
    "    # Sampling using the random number generator - Markov Chain Monte Carlo\n",
    "    trace = pm.sample(1000, tune=1000, random_seed=rng)\n",
    "\n",
    "\n",
    "# Summarize posterior\n",
    "print(pm.summary(trace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature SalePrice not found in posterior trace.\n",
      "Root Mean Squared Error (RMSE): 142167.9037710385\n"
     ]
    }
   ],
   "source": [
    "# Extract posterior means for each feature and intercept\n",
    "posterior_dist_feats = {}\n",
    "for feature in selected_features + ['Intercept']:\n",
    "    try:\n",
    "        # Attempt to access the posterior for the feature\n",
    "        if feature == 'Intercept':\n",
    "            # Intercept has no \"Effect\" suffix\n",
    "            arr = float(np.mean(trace.posterior['Intercept']))\n",
    "        else:\n",
    "            # Feature coefficients with \"Effect\" suffix\n",
    "            arr = float(np.mean(trace.posterior[f'{feature}Effect']))\n",
    "        \n",
    "        # Store the mean of the posterior distribution\n",
    "        posterior_dist_feats[feature] = arr\n",
    "\n",
    "    except KeyError:\n",
    "        # Handle cases where the posterior key does not exist\n",
    "        print(f\"Feature {feature} not found in posterior trace.\")\n",
    "        continue\n",
    "\n",
    "# Sort features by the magnitude of their coefficients (descending)\n",
    "train_features_coefficients = {k: v for k, v in sorted(posterior_dist_feats.items(), key=lambda i: abs(i[1]), reverse=True)}\n",
    "\n",
    "# Make predictions\n",
    "predictions = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    loc_arr = X_test.iloc[i]\n",
    "    prediction = 0\n",
    "    for k, v in train_features_coefficients.items():\n",
    "        if k == 'Intercept':\n",
    "            # Add intercept to the prediction\n",
    "            prediction += v\n",
    "        else:\n",
    "            # Add the weighted contribution of each feature\n",
    "            prediction += loc_arr[k] * v\n",
    "\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Evaluate using RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use normal distribution for the priors:\n",
    "Rationale: Normal priors are used here because they encode the belief that the parameter values are most likely to cluster around a central value (e.g., 0) but with some spread (controlled by the standard deviation, sigma).\n",
    "- #### Why It's Relevant:\n",
    "        - Most effects in real-world data tend to cluster around a central value (e.g., the effect of neighborhood or room size). The Normal distribution is flexible, allowing you to encode both uncertainty (using large sigma) and prior knowledge (using a specific mean, mu)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
